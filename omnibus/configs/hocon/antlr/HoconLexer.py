# flake8: noqa
# Generated from Hocon.g4 by ANTLR 4.8
from ...._vendor.antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys



def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\20")
        buf.write("\u00af\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
        buf.write("\t\23\4\24\t\24\4\25\t\25\3\2\3\2\3\3\3\3\3\4\3\4\3\5")
        buf.write("\3\5\3\6\3\6\3\7\3\7\3\b\3\b\3\t\3\t\3\t\5\t=\n\t\3\t")
        buf.write("\7\t@\n\t\f\t\16\tC\13\t\3\t\3\t\3\n\5\nH\n\n\3\n\3\n")
        buf.write("\3\n\6\nM\n\n\r\n\16\nN\3\n\5\nR\n\n\3\n\5\nU\n\n\3\n")
        buf.write("\3\n\3\n\3\n\5\n[\n\n\3\n\5\n^\n\n\3\13\3\13\3\13\7\13")
        buf.write("c\n\13\f\13\16\13f\13\13\3\13\3\13\3\13\3\13\7\13l\n\13")
        buf.write("\f\13\16\13o\13\13\3\13\5\13r\n\13\3\f\3\f\6\fv\n\f\r")
        buf.write("\f\16\fw\3\r\3\r\3\r\3\r\3\r\3\r\7\r\u0080\n\r\f\r\16")
        buf.write("\r\u0083\13\r\3\r\3\r\3\16\3\16\3\17\6\17\u008a\n\17\r")
        buf.write("\17\16\17\u008b\3\17\3\17\3\20\3\20\3\20\5\20\u0093\n")
        buf.write("\20\3\21\3\21\3\21\3\21\3\21\3\21\3\22\5\22\u009c\n\22")
        buf.write("\3\23\3\23\3\24\3\24\3\24\7\24\u00a3\n\24\f\24\16\24\u00a6")
        buf.write("\13\24\5\24\u00a8\n\24\3\25\3\25\5\25\u00ac\n\25\3\25")
        buf.write("\3\25\2\2\26\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13")
        buf.write("\25\f\27\r\31\16\33\17\35\20\37\2!\2#\2%\2\'\2)\2\3\2")
        buf.write("\17\4\2\f\f\17\17\3\2\62;\4\2$$^^\4\2))^^\4\2//aa\4\2")
        buf.write("<<??\5\2\13\f\17\17\"\"\n\2$$\61\61^^ddhhppttvv\5\2\62")
        buf.write(";C\\c|\5\2\62;CHch\3\2\63;\4\2GGgg\4\2--//\2\u00be\2\3")
        buf.write("\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2")
        buf.write("\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2")
        buf.write("\2\2\25\3\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2")
        buf.write("\2\35\3\2\2\2\3+\3\2\2\2\5-\3\2\2\2\7/\3\2\2\2\t\61\3")
        buf.write("\2\2\2\13\63\3\2\2\2\r\65\3\2\2\2\17\67\3\2\2\2\21<\3")
        buf.write("\2\2\2\23]\3\2\2\2\25q\3\2\2\2\27u\3\2\2\2\31y\3\2\2\2")
        buf.write("\33\u0086\3\2\2\2\35\u0089\3\2\2\2\37\u008f\3\2\2\2!\u0094")
        buf.write("\3\2\2\2#\u009b\3\2\2\2%\u009d\3\2\2\2\'\u00a7\3\2\2\2")
        buf.write(")\u00a9\3\2\2\2+,\7\60\2\2,\4\3\2\2\2-.\7.\2\2.\6\3\2")
        buf.write("\2\2/\60\7/\2\2\60\b\3\2\2\2\61\62\7}\2\2\62\n\3\2\2\2")
        buf.write("\63\64\7\177\2\2\64\f\3\2\2\2\65\66\7]\2\2\66\16\3\2\2")
        buf.write("\2\678\7_\2\28\20\3\2\2\29=\7%\2\2:;\7\61\2\2;=\7\61\2")
        buf.write("\2<9\3\2\2\2<:\3\2\2\2=A\3\2\2\2>@\n\2\2\2?>\3\2\2\2@")
        buf.write("C\3\2\2\2A?\3\2\2\2AB\3\2\2\2BD\3\2\2\2CA\3\2\2\2DE\b")
        buf.write("\t\2\2E\22\3\2\2\2FH\7/\2\2GF\3\2\2\2GH\3\2\2\2HI\3\2")
        buf.write("\2\2IJ\5\'\24\2JL\7\60\2\2KM\t\3\2\2LK\3\2\2\2MN\3\2\2")
        buf.write("\2NL\3\2\2\2NO\3\2\2\2OQ\3\2\2\2PR\5)\25\2QP\3\2\2\2Q")
        buf.write("R\3\2\2\2R^\3\2\2\2SU\7/\2\2TS\3\2\2\2TU\3\2\2\2UV\3\2")
        buf.write("\2\2VW\5\'\24\2WX\5)\25\2X^\3\2\2\2Y[\7/\2\2ZY\3\2\2\2")
        buf.write("Z[\3\2\2\2[\\\3\2\2\2\\^\5\'\24\2]G\3\2\2\2]T\3\2\2\2")
        buf.write("]Z\3\2\2\2^\24\3\2\2\2_d\7$\2\2`c\5\37\20\2ac\n\4\2\2")
        buf.write("b`\3\2\2\2ba\3\2\2\2cf\3\2\2\2db\3\2\2\2de\3\2\2\2eg\3")
        buf.write("\2\2\2fd\3\2\2\2gr\7$\2\2hm\7)\2\2il\5\37\20\2jl\n\5\2")
        buf.write("\2ki\3\2\2\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2mn\3\2\2\2n")
        buf.write("p\3\2\2\2om\3\2\2\2pr\7)\2\2q_\3\2\2\2qh\3\2\2\2r\26\3")
        buf.write("\2\2\2sv\5#\22\2tv\t\6\2\2us\3\2\2\2ut\3\2\2\2vw\3\2\2")
        buf.write("\2wu\3\2\2\2wx\3\2\2\2x\30\3\2\2\2yz\7&\2\2z{\7}\2\2{")
        buf.write("|\3\2\2\2|\u0081\5\27\f\2}~\7\60\2\2~\u0080\5\27\f\2\177")
        buf.write("}\3\2\2\2\u0080\u0083\3\2\2\2\u0081\177\3\2\2\2\u0081")
        buf.write("\u0082\3\2\2\2\u0082\u0084\3\2\2\2\u0083\u0081\3\2\2\2")
        buf.write("\u0084\u0085\7\177\2\2\u0085\32\3\2\2\2\u0086\u0087\t")
        buf.write("\7\2\2\u0087\34\3\2\2\2\u0088\u008a\t\b\2\2\u0089\u0088")
        buf.write("\3\2\2\2\u008a\u008b\3\2\2\2\u008b\u0089\3\2\2\2\u008b")
        buf.write("\u008c\3\2\2\2\u008c\u008d\3\2\2\2\u008d\u008e\b\17\2")
        buf.write("\2\u008e\36\3\2\2\2\u008f\u0092\7^\2\2\u0090\u0093\t\t")
        buf.write("\2\2\u0091\u0093\5!\21\2\u0092\u0090\3\2\2\2\u0092\u0091")
        buf.write("\3\2\2\2\u0093 \3\2\2\2\u0094\u0095\7w\2\2\u0095\u0096")
        buf.write("\5%\23\2\u0096\u0097\5%\23\2\u0097\u0098\5%\23\2\u0098")
        buf.write("\u0099\5%\23\2\u0099\"\3\2\2\2\u009a\u009c\t\n\2\2\u009b")
        buf.write("\u009a\3\2\2\2\u009c$\3\2\2\2\u009d\u009e\t\13\2\2\u009e")
        buf.write("&\3\2\2\2\u009f\u00a8\7\62\2\2\u00a0\u00a4\t\f\2\2\u00a1")
        buf.write("\u00a3\t\3\2\2\u00a2\u00a1\3\2\2\2\u00a3\u00a6\3\2\2\2")
        buf.write("\u00a4\u00a2\3\2\2\2\u00a4\u00a5\3\2\2\2\u00a5\u00a8\3")
        buf.write("\2\2\2\u00a6\u00a4\3\2\2\2\u00a7\u009f\3\2\2\2\u00a7\u00a0")
        buf.write("\3\2\2\2\u00a8(\3\2\2\2\u00a9\u00ab\t\r\2\2\u00aa\u00ac")
        buf.write("\t\16\2\2\u00ab\u00aa\3\2\2\2\u00ab\u00ac\3\2\2\2\u00ac")
        buf.write("\u00ad\3\2\2\2\u00ad\u00ae\5\'\24\2\u00ae*\3\2\2\2\31")
        buf.write("\2<AGNQTZ]bdkmquw\u0081\u008b\u0092\u009b\u00a4\u00a7")
        buf.write("\u00ab\3\b\2\2")
        return buf.getvalue()


class HoconLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    COMMENT = 8
    NUMBER = 9
    STRING = 10
    PATH_ELEMENT = 11
    REFERENCE = 12
    KV = 13
    WS = 14

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'.'", "','", "'-'", "'{'", "'}'", "'['", "']'" ]

    symbolicNames = [ "<INVALID>",
            "COMMENT", "NUMBER", "STRING", "PATH_ELEMENT", "REFERENCE", 
            "KV", "WS" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "COMMENT", "NUMBER", "STRING", "PATH_ELEMENT", "REFERENCE", 
                  "KV", "WS", "ESC", "UNICODE", "ALPHANUM", "HEX", "INT", 
                  "EXP" ]

    grammarFileName = "Hocon.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None
